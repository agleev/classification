# Задачи классификации
Привет!
В этом репозитории лежат мои первые проекты по классификации данных, которые я загружал на [kaggle](https://www.kaggle.com/agleev). Я брал данные, делал проект в Jupiter Notebook и выгружал на сайт. Только после этого я решил загрузить сюда, на github. В них нет контроля версий, нет отдельных файлов с заданными функциями и даже нет файла readme. Честно признаться, и некоторые проекты имеют недостатки, которые я увидел лишь спустя время.

Как оказалось потом, большая часть данных по задачам классификации и регрессии - искусственные, не очень интересно работать с ними дальше. Если прогнать их по алгоритмам с дефолтными настройками, то они покажут отличные показатели метрик качества даже без предобработки данных.

Ниже расскажу о каждом проекте и недостатках, которые в нем есть. Отдельная папка - отдельный проект с файлом данных .csv и файлом проекта.

## 01_xgboost_with_parameter_tuning

[Diabetes Health Indicators Dataset](https://www.kaggle.com/alexteboul/diabetes-health-indicators-dataset) - набор данных с показателями здоровья и наличием и остуствием диабета. Данные собирались в ходе телефонного опроса американцев, одни переменные - это прямые ответы на вопросы, другие - расчетные переменные, которые были основаны на ответах. Датасет не имеет пропусков и сбалансирован (таргет - 50% на 50%).

1. Я разделил переменные на непрерывные и категориальные.
2. Категориальные переменные я разбил на отдельные признаки со значением - 1 и 0.
3. Непрерыную переменную с индексом массы тела `bmi` я заменил на группы, исходя из [общепринятой таблицы значений](https://ru.wikipedia.org/wiki/%D0%98%D0%BD%D0%B4%D0%B5%D0%BA%D1%81_%D0%BC%D0%B0%D1%81%D1%81%D1%8B_%D1%82%D0%B5%D0%BB%D0%B0).
4. Прошкалировал непрерывные переменные.
5. Запустил алгоритм `XGBClassifier` на дефолтных настройках, чтобы было с чем сравнить.
6. Задал функцию обучения, с перекрестной проверкой и автоматическим поиском параметров. Настроил ноутбук так, чтобы можно было просто запустить и все.
7. Алгоритм сначала подобрал значение `n_estimators` и `learning_rate` потом снова перепроверил, но уже на соседних значениях. И так по остальным гиперпараметрам: `max_depth`, `min_child_weight`, `subsample`, `colsample_bytree`, `gamma`. С каджды последующим шагом они автоматически добавлялись в классификатор.
8. Логичстическая функция потерь нашего классификатора уменьшилась с 0.516 до 0.5.

[Diabetes Health Indicators Dataset](https://www.kaggle.com/agleev/xgboost-with-parameter-tuning) - мой проект на kaggle.

## 02_employee_future_prediction_pr_0.97

[Employee Future Prediction](https://www.kaggle.com/tejashvi14/employee-future-prediction) - набор данных, где нужно предсказать увольнение сотрудника - 1 или 0. Признаки - филиал компании, уровень зарплаты, образование, пол, возраст и время работы.

Анализ данных показал:
- во всех филиалах женщинам платили меньше, чем мужчинам;
- в филиале, в Пуне, уволилось очень много женщин, осталось работать в несколько раз меньше;
- кто устроился на работу в 2018 году получали большую заработную плату и почти все уволились.

Как потом показал алгоритм, на обучение как раз сильно повлияли эти признаки - пол, год, город и уровень оплаты. И я получил высокий `pressusion` и низкий `recall` - 0.9 и 0.5 соответсвенно. Чтобы алгоритм правильнее предсказывал факт увольнения, правильней было бы нивелировть массовое увольнение женщин в Пуне и сотрудников, работающих с 2018 года.

[EDA with mean() + groupby(). pr: 0.94 (0.97)](https://www.kaggle.com/agleev/eda-with-mean-groupby-pr-0-94-0-97) - мой проект на kaggle.
